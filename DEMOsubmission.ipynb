{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pydicom\n",
    "\n",
    "import kaggle_evaluation.rsna_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7082c",
   "metadata": {},
   "source": [
    "The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in rsna_gateway will run in a different container with direct access to the hidden test set and hand off the data series by series.\n",
    "\n",
    "Your code will always have access to the published copies of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL = 'SeriesInstanceUID'\n",
    "\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present',\n",
    "]\n",
    "\n",
    "# All tags (other than PixelData and SeriesInstanceUID) that may be in a test set dcm file\n",
    "DICOM_TAG_ALLOWLIST = [\n",
    "    'BitsAllocated',\n",
    "    'BitsStored',\n",
    "    'Columns',\n",
    "    'FrameOfReferenceUID',\n",
    "    'HighBit',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'Modality',\n",
    "    'PatientID',\n",
    "    'PhotometricInterpretation',\n",
    "    'PixelRepresentation',\n",
    "    'PixelSpacing',\n",
    "    'PlanarConfiguration',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'RescaleType',\n",
    "    'Rows',\n",
    "    'SOPClassUID',\n",
    "    'SOPInstanceUID',\n",
    "    'SamplesPerPixel',\n",
    "    'SliceThickness',\n",
    "    'SpacingBetweenSlices',\n",
    "    'StudyInstanceUID',\n",
    "    'TransferSyntaxUID',\n",
    "]\n",
    "\n",
    "# Replace this function with your inference code.\n",
    "# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n",
    "# Each prediction (except the very first) must be returned within 30 minutes of the series being provided.\n",
    "def predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    # --------- Replace this section with your own prediction code ---------\n",
    "    series_id = os.path.basename(series_path)\n",
    "    \n",
    "    all_filepaths = []\n",
    "    for root, _, files in os.walk(series_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                all_filepaths.append(os.path.join(root, file))\n",
    "    all_filepaths.sort()\n",
    "    \n",
    "    # Collect tags from the dicoms\n",
    "    tags = defaultdict(list)\n",
    "    tags['SeriesInstanceUID'] = series_id\n",
    "    global dcms\n",
    "    for filepath in all_filepaths:\n",
    "        ds = pydicom.dcmread(filepath, force=True)\n",
    "        tags['filepath'].append(filepath)\n",
    "        for tag in DICOM_TAG_ALLOWLIST:\n",
    "            tags[tag].append(getattr(ds, tag, None))\n",
    "        # The image is in ds.PixelData\n",
    "\n",
    "    # ... do some machine learning magic ...\n",
    "    predictions = pl.DataFrame(\n",
    "        data=[[series_id] + [0.5] * len(LABEL_COLS)],\n",
    "        schema=[ID_COL, *LABEL_COLS],\n",
    "        orient='row',\n",
    "    )\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == [ID_COL, *LABEL_COLS]\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == [ID_COL, *LABEL_COLS]).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "\n",
    "    # ----------------------------- IMPORTANT ------------------------------\n",
    "    # You MUST have the following code in your `predict` function\n",
    "    # to prevent \"out of disk space\" errors. This is a temporary workaround\n",
    "    # as we implement improvements to our evaluation system.\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    return predictions.drop(ID_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f74d31",
   "metadata": {},
   "source": [
    "When your notebook is run on the hidden test set, inference_server.serve must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first predict call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187deec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway()\n",
    "    display(pl.read_parquet('/kaggle/working/submission.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
